{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4Y20uWiqC_o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import progressbar as pb\n",
    "import time\n",
    "import warnings\n",
    "import text_processing as tp\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcgC4k6LqC_t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove NA\n",
      "Before removing the NaN:\n",
      "id                 0\n",
      "product            0\n",
      "component          0\n",
      "reporter           0\n",
      "bug_status         0\n",
      "resolution         0\n",
      "priority           0\n",
      "bug_severity       0\n",
      "version            0\n",
      "short_desc         1\n",
      "opendate           0\n",
      "dup_list        1499\n",
      "root_id         1406\n",
      "disc_id         1406\n",
      "dtype: int64\n",
      "\n",
      "After removing the NaN:\n",
      " id                 0\n",
      "product            0\n",
      "component          0\n",
      "reporter           0\n",
      "bug_status         0\n",
      "resolution         0\n",
      "priority           0\n",
      "bug_severity       0\n",
      "version            0\n",
      "short_desc         0\n",
      "opendate           0\n",
      "dup_list        1498\n",
      "root_id         1405\n",
      "disc_id         1405\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv('TestData2500.csv',sep=',')\n",
    "# Remove nan from the main dataset\n",
    "tp.remove_nan(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YSGUykkOqC_w",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (3 of 1594) |                       | Elapsed Time: 0:00:00 ETA:   0:01:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (1592 of 1594) |################### | Elapsed Time: 0:01:04 ETA:   0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove NA\n",
      "Before removing the NaN:\n",
      "id                         0\n",
      "short_desc_processed       0\n",
      "product                    0\n",
      "component                  0\n",
      "reporter                   0\n",
      "bug_status                 0\n",
      "resolution                 0\n",
      "priority                   0\n",
      "bug_severity               0\n",
      "version                    0\n",
      "short_desc                 0\n",
      "opendate                   0\n",
      "dup_list                1498\n",
      "root_id                 1405\n",
      "disc_id                 1405\n",
      "dtype: int64\n",
      "\n",
      "After removing the NaN:\n",
      " id                         0\n",
      "short_desc_processed       0\n",
      "product                    0\n",
      "component                  0\n",
      "reporter                   0\n",
      "bug_status                 0\n",
      "resolution                 0\n",
      "priority                   0\n",
      "bug_severity               0\n",
      "version                    0\n",
      "short_desc                 0\n",
      "opendate                   0\n",
      "dup_list                1498\n",
      "root_id                 1405\n",
      "disc_id                 1405\n",
      "dtype: int64\n",
      "Text preprocessing --- 64.16023778915405 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the short_desc\n",
    "processed_data_df = tp.text_preprocessing(data,\"short_desc\")\n",
    "# Save to file to save time\n",
    "processed_data_df.to_csv('processed_TestData2500_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BerhLMLBqC_z",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Load prosecced df from file to sasve time\n",
    "processed_data_df = pd.read_csv('processed_TestData2500_df.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlpjDsOiqC_1",
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model-1: Similarity Score - Word2vec -------------------------------------------------------------------------\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "execution_count_word2vec = 0\n",
    "processed_data_nlp_df = []\n",
    "\n",
    "# Convert short_desc str to nlp format to fasten the computation process \n",
    "def word2vec_preprocess(df):\n",
    "    print('Convert short_desc str to nlp format')\n",
    "    sample_size = len(df)\n",
    "    progress = pb.ProgressBar(maxval = sample_size).start()\n",
    "    progvar  = 0\n",
    "    processed_data_nlp = []\n",
    "    for tup in df.itertuples():\n",
    "        processed_data_nlp.append((tup.id,tup.product,nlp(tup.short_desc_processed))) \n",
    "        progress.update(progvar + 1)\n",
    "        progvar += 1\n",
    "    global processed_data_nlp_df\n",
    "    processed_data_nlp_df = pd.DataFrame(processed_data_nlp, columns=['id','product','short_desc_processed'])\n",
    "    global execution_count_word2vec\n",
    "    execution_count_word2vec += 1\n",
    "\n",
    "# Calculate the cosine similarity score\n",
    "def word2vec_similarity(id,df):\n",
    "    if execution_count_word2vec == 0:\n",
    "        word2vec_preprocess(df)\n",
    "    similarities_score_list = []\n",
    "    product_main = processed_data_nlp_df.loc[lambda df: df['id'] == id,'product'].array[0]\n",
    "    short_desc_processed_main = processed_data_nlp_df.loc[lambda df: df['id'] == id,'short_desc_processed'].array[0]\n",
    "    for doc in processed_data_nlp_df.itertuples():\n",
    "        product_other = processed_data_nlp_df.loc[lambda df: df['id'] == doc.id,'product'].array[0]\n",
    "        if product_main == product_other:\n",
    "            similarity_score = doc.short_desc_processed.similarity(short_desc_processed_main)\n",
    "            similarities_score_list.append((doc.id,similarity_score))\n",
    "    #convert to dataframe\n",
    "    word2vec_similarities_score_df = pd.DataFrame(similarities_score_list, columns=['id','word2vec_score'] )\n",
    "    word2vec_similarities_score_df = word2vec_similarities_score_df.reset_index(drop=True)\n",
    "    return word2vec_similarities_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gU1hrZ1qC_3",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model-2: Similarity Score - TF-idf ----------------------------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "tfidf_cosine_similarities = []\n",
    "execution_count_tfidf = 0\n",
    "\n",
    "def tfidf_preprocess(df):\n",
    "    X_train = df['short_desc_processed']\n",
    "    print('TF-idf Vectorization and similarity score computation')\n",
    "    # Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(X_train)\n",
    "    # Calculate the cosine similarity score\n",
    "    global tfidf_cosine_similarities\n",
    "    tfidf_cosine_similarities = linear_kernel(tfidf)\n",
    "    global shape_tfidf\n",
    "    shape_tfidf = tfidf_cosine_similarities.shape[0]\n",
    "    print('TF-idf preprocess done')\n",
    "    global execution_count_tfidf\n",
    "    execution_count_tfidf += 1\n",
    "\n",
    "def tfidf_similarities(id,df):\n",
    "    if execution_count_tfidf == 0:\n",
    "        tfidf_preprocess(df)\n",
    "    index_main   = df.loc[lambda df: df['id'] == id].index.array[0]\n",
    "    product_main = df.loc[lambda df: df['id'] == id,'product'].array[0]\n",
    "    tfidf_cosine_similarities_list = []\n",
    "    for index_other in range(shape_tfidf):\n",
    "        id_other      = df.iloc[index_other]['id']\n",
    "        product_other = df.iloc[index_other]['product']\n",
    "        if product_main == product_other:\n",
    "            tfidf_cosine_similarities_list.append([id_other,tfidf_cosine_similarities[index_main,index_other]])\n",
    "    #Conver to dataframe\n",
    "    tfidf_cosine_similarities_score_df = pd.DataFrame(tfidf_cosine_similarities_list, columns=['id','tfidf_score'])\n",
    "    tfidf_cosine_similarities_score_df = tfidf_cosine_similarities_score_df.reset_index(drop=True)\n",
    "    return tfidf_cosine_similarities_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5wlDGp3qC_6",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Model-3: Similarity Score - BM24F -----------------------------------------------------------------------------\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "processed_corpus_list = []\n",
    "bm25 = []\n",
    "execution_count_bm25 = 0\n",
    "\n",
    "# preprocess - tokenize the short_desc to token\n",
    "def bm24_preprocess(df):\n",
    "    print('preprocess - tokenize the short_desc to token')\n",
    "    sample_size = len(df)\n",
    "    global processed_corpus_list\n",
    "    processed_corpus_list = []\n",
    "    for x in df.itertuples():\n",
    "        short_desc_splited = x.short_desc_processed.split(\" \")\n",
    "        processed_corpus_list.append(short_desc_splited)\n",
    "    # Create a MB24 Object with the corpus\n",
    "    global bm25\n",
    "    bm25 = BM25Okapi(processed_corpus_list)\n",
    "    global execution_count_bm25\n",
    "    execution_count_bm25 += 1\n",
    "    \n",
    "# Calculate the similarity score\n",
    "def bm24_similarity(id,df):\n",
    "    if execution_count_bm25 == 0:\n",
    "        bm24_preprocess(df)\n",
    "    index_main    = df.loc[lambda df: df['id'] == id].index.array[0]\n",
    "    product_main  = df.loc[lambda df: df['id'] == id,'product'].array[0]\n",
    "    query         = processed_corpus_list[index_main]\n",
    "    doc_scores    = bm25.get_scores(query)\n",
    "    doc_scores_df = pd.DataFrame(doc_scores, columns=['bm24_score'])\n",
    "    # add id to the score list and remove unsimiliar product\n",
    "    blanks = []\n",
    "    for x in doc_scores_df.itertuples():\n",
    "        id_other      = df.iloc[x.Index]['id']\n",
    "        product_other = df.iloc[x.Index]['product']\n",
    "        # add id to the score list\n",
    "        doc_scores_df.loc[x.Index,'id'] = id_other\n",
    "        if product_main != product_other:\n",
    "            blanks.append(x.Index)    \n",
    "    doc_scores_df.drop(blanks,inplace=True)   \n",
    "    doc_scores_df = doc_scores_df.reset_index(drop = True)  \n",
    "    return doc_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z8EslEyqC_8"
   },
   "source": [
    "Assessment the Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikHJjrkvqC_9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assessment the Model Accuracy -------------------------------------------------------------------------------\n",
    "# duplicate_df = pd.read_csv('https://zenodo.org/record/400614/files/apache.relations.csv?download=1',sep=',')\n",
    "duplicate_df = pd.read_csv('duplicate_df.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qFg56-HqC__",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the similarity scores and return the first n top scoes\n",
    "def similarity_score(id, df,top_n):\n",
    "    word2vec_similarity_df = word2vec_similarity(id, df).sort_values(by=['word2vec_score'],ascending=False).head(top_n)\n",
    "    tfidf_similarity_df    = tfidf_similarities(id, df).sort_values(by=['tfidf_score'],ascending=False).head(top_n)\n",
    "    bm24_similarity_df     = bm24_similarity(id, df).sort_values(by=['bm24_score'],ascending=False).head(top_n)    \n",
    "    return word2vec_similarity_df, tfidf_similarity_df, bm24_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgayCI1DqDAC",
    "outputId": "f01c78d2-a083-44ac-f740-744535e96df2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (83 of 83) |########################| Elapsed Time: 0:03:00 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Total- 180.82528567314148 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Calculate the similarity score for the reported duplicated bug report\n",
    "start_time  = time.time()\n",
    "sample_size = len(duplicate_df)\n",
    "progress    = pb.ProgressBar(maxval = sample_size).start()\n",
    "progvar     = 0\n",
    "duplicated_similarity_score_list = []\n",
    "\n",
    "for tup in duplicate_df.itertuples():\n",
    "    word2vec_similarity_df, tfidf_similarity_df, bm24_similarity_df = similarity_score(tup.id, processed_data_df,10)\n",
    "    duplicated_similarity_score_list.append([tup.id,tup.dup,word2vec_similarity_df,tfidf_similarity_df,bm24_similarity_df])\n",
    "    progress.update(progvar + 1)\n",
    "    progvar += 1\n",
    "    \n",
    "print(\"-Total- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DtDQ8rhqDAF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the list to a file since it takes 8 hours to create it\n",
    "# with open(\"duplicated_similarity_score_list_2500.txt\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(duplicated_similarity_score_list, fp)\n",
    "\n",
    "# # Read the list from a file \n",
    "# with open(\"duplicated_similarity_score_list_2500.txt\", \"rb\") as fp:   # Unpickling\n",
    "#     duplicated_similarity_score_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKSY0w_cqJXg"
   },
   "outputs": [],
   "source": [
    "# Calculate the Recall rate\n",
    "def recall_rate_calculation(name_of_algorthem):\n",
    "    if name_of_algorthem == 'word2vec':\n",
    "        select_algorithm = 2\n",
    "        print('word2vec result:')\n",
    "    elif name_of_algorthem == 'tfidf':\n",
    "        select_algorithm = 3\n",
    "        print('TF-idf result:')\n",
    "    elif name_of_algorthem == 'bm24':\n",
    "        select_algorithm = 4\n",
    "        print('bm24 result:')\n",
    "    else:\n",
    "        return \"Wrong selection\"\n",
    "    found_counter = 0\n",
    "    not_found_counter = 0\n",
    "    for x in duplicated_similarity_score_list:\n",
    "        dup = x[1]\n",
    "        df = x[select_algorithm]\n",
    "        if df.loc[df['id'] == dup].empty:\n",
    "            not_found_counter +=1\n",
    "        else:\n",
    "            found_counter +=1\n",
    "    print('Num of duplicated report found: ',found_counter)\n",
    "    print('Num of duplicated report not found: ',not_found_counter)\n",
    "    print('Recall (TP/TP+FN): ', round(found_counter/len(duplicated_similarity_score_list)*100,2),'%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8uPULPPqa4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec result:\n",
      "Num of duplicated report found:  37\n",
      "Num of duplicated report not found:  46\n",
      "Recall (TP/TP+FN):  44.58 %\n",
      "\n",
      "TF-idf result:\n",
      "Num of duplicated report found:  42\n",
      "Num of duplicated report not found:  41\n",
      "Recall (TP/TP+FN):  50.6 %\n",
      "\n",
      "bm24 result:\n",
      "Num of duplicated report found:  41\n",
      "Num of duplicated report not found:  42\n",
      "Recall (TP/TP+FN):  49.4 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the results\n",
    "recall_rate_calculation('word2vec')\n",
    "recall_rate_calculation('tfidf')\n",
    "recall_rate_calculation('bm24')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAABGCAIAAADzfsfRAAAOOElEQVR4Ae1cbUxcRRc+if4wrTFKhFhMGlprVVZlG2xKiOne+NUEl9Ti0hUr0LcU08aIaFjQdvcu2jYW04BG+wFha6EkfASUfii17F5am9QqpK3Z0tjahoo26kvARvun5c65b15OGG93l/3isgX23j87O3PmzJlnnntm5szsgqI/OgIaIPDf1v8sXLhwIWigSlehIzCOgM6ncST0Ty0Q0PmkBYq6jnEEdD6NI6F/aoGAzictUNR1jCOg82kcCf1TCwR0PmmBoq5jHAGdT+NI6J9aIKDzSQsUdR3jCOh8GkdC/9QCAZ1PWqCo6xhHQOfTOBL6pxYI6HzSAkVF+fvvv7VRNMO16HzSYAARcfny5WpFiHj48OFFixa5XC7GGBWdOHHi2LFjarHZl9b5pMGYIiLAv0ieP3/earUCwMjIyOeff75gwYLh4WFFUXQ+aYB1PKhQ84kxJgiCx+PhHc/JyWlra1MU5dtvv9X9E4dFT0yIAOcTIr799ttOp1MtWlZWZrVaEVHnkxoWPT0hAoiYl5enKApjLCUlpaenRy2ak5Njs9kURTl+/Ljun9TI6OnACHA+Xbx48d5770VELjcyMjJ//nya746NPbxoVib+XUXOyu7FplOcT5IkLV68WM2nzz77LCcnh7Z4Op9iMxy3rRU29jgcDlEUJ2ME5xMtxk+fPp2ammowGDo6OgCAxwumiE+IyBirqakxmUxqKk+mR1HXjV//xBibO3fuo48+CgCT5xOPF0iS9PTTT69fvx7GHlmW+dhMBZ8Qcc6cOcuXLwcAnU8c6tuTYIwtXrxYWz4pioKITqezq6tr3759jY2N1dXV1L2p4BNtAmRZ1vl0ezjk02pxcbHmfKImfvnlFwDIzc2d6vmOGKzzyWdkb8/Xs2fPasIns9ns0wFEvHr1KicTxQuOHz/uI6bJVwqA6fOdJmBOSslPP/0EANu2bZuUlrAr37hxI2zZCAQ5n9T0jaC+dqLxux4nDGlWamhoiBRSr9d7eOLn0KFD6sIDBw588cUX7e3tra2tX3755ZEjR7TdiHE+aas2UkwURYl3Pv35558A0NLSEil2vb29CQkJACAIQnZ29po1a4qLi0tLSzdv3iz6PevXrzebzcnJybTpA4DLly9H2mIQeZ1PQcCJadG1a9ei4xMifvLJJ8SPjRs3hnQMFOs6evRoXl4eAJSWlmo4N+l8iilpgjR248aN6PhEG/Xc3Fyi1KeffhqkFXURIm7fvn3+/PkjIyPq/MmkZxKfGGOyLDPGJnoFGWOjo6MkQG8hVaFalKMGSy3D0xMpV1fUNs0Ys9vtoigCwLPPPhtdlLy/v3/evHkAcOedd6rvqIQ0dceOHRUVFSHFQgogIu+FIAh2u93hcMQeTG5niPUTY4zev4cffjjgdrS+vp4EDAbD0aNHKVBLOSaTCQAyMzOrqqpGR0d5k3a7nQQAgMKJjz32WFlZ2dmzZ2MJBCJ2dna23PpwI8NP7Nmzh7qTlpb2xx9/hFkREd1ud5jCQcT8e9Hc3BxLGH1sC8En8uoej2fLli0AcP78eXV9xlhaWhrFb7h/4rFa7qVEUXzkkUf4yQOdNxHbyLExxlwu13333dfX13cbsVB3Lfw0Ir722mtEqYKCghlnf/g9DUcyNJ8URfF4PDk5OQCwYcMGtdKGhoaNGzf6xAPJpRUVFXFJYlhubi7PQUTik3pNKggCAPzwww9cbKYkLl269NBDDxGldu/ePVPMngo7w+WTxWIpLCxMTEzkLh0RV65c+fPPPwfkk/qElRiWkJDAO8D5xJ0WncwDwOnTp7nYDEq0t7cTn5KSkn788ccZZLm2pobLp7y8PI/HAwB8I/P9999nZ2ePjo4G5xMiVldX+8hwPnH/dOLEibvuustisUw0X2CoR1tcotBGS3sAWLlyJe9XFHpmdJVw+bR27VrGmMlkeuaZZ2jIlyxZ0tnZSXOZvzdyOBx2u724uNhsNhsMhvr6ejXEnE92u/2NN96wWq2CILz33nvcXflg+ttvv5lCPT5VYv+VMbZq1SryUqIoTvRixN6wWLYYLp9ef/11RVEogtfb24uIBQUFtNv38T00uzkcDnnsoQiN1+tV94rzidbj9GYXFhYGGQMeWaAEX8jzfLV+nj6j3cN1BkkMDg4++eSTRKmOjo4gkgGLtDM2Yk0XL14MaFKkmWHxSZKkN998U1GUK1euzJkzp6Kioqury+Vy0e4vIJ+4x6KF0bJly9S+h/OJOy2HwwEAFy5ciLQDweVFUTRq9ARviJd2dXURn1588UWeGWaisrJSI2MjVhNrPpWVldE9G6vVSnca6QSKvBFnD2dYRUUFORuaJQHg3LlzHFbOJ04yWs8G2Rz5nYn5ZgTxbbzdGCRkWab4CH9VYtDo9GkiLP/U09OzadMmMtrlcgFAfn4+p0tA/8QnL0Rct24dADQ2NiqKQr/04HzioLvdbgAoKChQFKWvr8/nJ0eKotwadwzwbZpg+vHHH6vvjE8Tq8I348KFC5s2bfr999/Dr6KWDMEnRBwaGlq9enVqaqrD4ZAk6fLlywDQ1NREEV7a9DmdTvf4QznPPfec2+2mIwjKKSkpoWOm7u5ut9tN0SYuMzQ0lJycbDQaEbGoqOjkyZNqK2dKurGxEQCiHozp0E2bzQYAH374YXTGhOATY0wUxdLSUsvYI0kSIu7atYui4T5TjtvtfvXVV0VRXLduHRURnxhjLS0t5eXlgiB0dnb61KK5EhG7uro++OADk8kkiiL3W9H1yr9Wb2/vzZs3/fOD50QUXD116hQAdHd3B9cZs1I6V5UkKaIWf/31123btv31118R1eLCIfjE5SafoPhRcD10FBNcJrrSd999N+CSExG9Xm9tba3T6Tx8+LB6EYaI99xzT5jMHhwcvPvuu6O4RxVdd0LWYoxVVVX5LEVC1pq8QOz4NHlbJ6PBn0+MMa/Xm5+fn5WVtWPHjqampieeeCIrK2tgYIAaotk5HD4xxjIzM3fu3KmmY3BrEVG9iQkuHF0pIgqCMNWt+NgWL3yqqKhQ+yf6f6aEhAT13CrLsslkys7OJlqEySfG2IYNGyorK8Mnk6IoO3furKqq8hkMbb/qfNIWz1u0+fDp3LlzDz74oP+18ZqaGgD45ptv+I+QgvsnRHz//fcjulbAGKuurp47d244V345R2klQMFbnnlLD8f+jUN9TY0if3x5ShomquujKuqv8eKfysvLuX+6fv26yWRasWKFP7gUtqAwWEj/hIj19fUZGRkhOUdjKctye3t7fn4+ALzyyisBa508eTJx7HE4HAsWLBAE4eDBgxQuyc/Pt9vtGRkZdPZA9z5WrFiRmJi4ZcsWURQFQTAajfyohyJ/xCez2UxRVgDw73XU7PGvGHd8QsS9e/cCQMDppqGhAQD27dtH/umFF14IOOqE49dff33//ffTxU7/TWtZWVlRUdGqVatMJpPBYEhMTOQjypvwHw9E5Nd76Ky9trb2/78bGfvhg6IosiynpKRQMA8Rv/vuOwBISkqid6C6utpgMJDNav/U09OTlZW1f//+IN3xNyaKnHjhk81mI//EGCspKQGAq1ev+uO1detWACBJRAzCpzNnzqSkpKgpElE6yLgSD1566SU6bCAjBwcHvV4v+Tmz2SwIArkZn/MJCvVx5bQeF0UxMzOTZ5LC2tpaQRD8EZhkTtzxaXR01Gg0PvDAA/5unzFmNBoff/xxgh4Rn3/+eZ9h4HCrFzT8TJon1HfneaY64d8610x8euutt3gOuaXt27cbDIbVq1cLgsDvXgfhE1+PA4DRaPznn3/UCgcGBoLYoJaMKB13fKIBWLZsmT+aR44codAwFQXnU0QoRyQsy7LPPp9stlgsdKuCbu7IsswnRx4UIP/ET0UFQXjnnXdkWU5PT+frKkVRhoeHIwrVhm9/PPIpPT194cKF5GAuXbpEN04ZYxaLRT0vTAWf/M8lAw5VSkpKZWUlL6L7PMQS8jomk6murq65uZmWVkH4REW7d+8GgAMHDiiKcu3aNVLoc4mINzeZRNzxiQKJADAwMFBeXg4Aqampg4ODFotl0aJF/M2m9XiQ+U4NuiAItGpWZ/qkRVGk9Za/X1RLSpJEg11ZWcljY4yx9PR0u91OK/TNmzcLguB0OkVRpF/XOJ1Oi8VCewLaaoiiaLFYSMxqtdJ1IIPBYLFY3G63JElPPfWU5reD4uj35nw9Totcq9W6dOlSupVlt9utVqvNZvNZKoWMF6h5EDKNiJIkhdyuS5LU3NxM1ye2bt3KTRoeHj506JDT6WxtbUXEurq6r776SpKk7u5uEna5XKIo0vl6d3e3KIptbW3qor179zY0NLjdbsZYU1NTVlZWcGaH7FFAgbjzT4QCY6yurq6wsNBsNtNrTeBmZGRwlMPkk8vl2rNnD6md6I47lYbDp4CDpHlmYWGhy+Wifx3WVnmc8olApOGXJGnevHkdHR0lJSUfffQRxzccPh08ePDUqVO0FGtra1se6Hn55ZdJJ/GJuxzeUOwTNpstOTl5Kk6v45pPNJBXrlyh0NGSJUuuX7/ORzccPh07dqy1tZXv3rl/onMP/pV0Th//xPuoeSJe+JSWlsbPW3xARESPx7N///6hoSF1ESLecccdId3JmjVrdu3a1dfX19/f7x8lpxxSq/NJDe/MTjc2Nvb390fUB0Ssqanhy6mAdcmH3bx5c+nSpbTSVwcteZrqTp/5LmBfNMmMF/+kCVgBlaxduzYpKSmkG3OOPaIoUiKgqlmQqfNpFgziNOqCzqdpNBizwBSdT7NgEKdRF3Q+TaPBmAWm6HyaBYM4jbqg82kaDcYsMEXn0ywYxGnUBZ1P02gwZoEp/wMaNRGSL5BFgAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the MRR \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MRR\n",
    "def MRR_rate_calculation(name_of_algorthem):\n",
    "    if name_of_algorthem == 'word2vec':\n",
    "        select_algorithm = 2\n",
    "        print('word2vec result:')\n",
    "    elif name_of_algorthem == 'tfidf':\n",
    "        select_algorithm = 3\n",
    "        print('TF-idf result:')\n",
    "    elif name_of_algorthem == 'bm24':\n",
    "        select_algorithm = 4\n",
    "        print('bm24 result:')\n",
    "    else:\n",
    "        return \"Wrong selection\"\n",
    "    found_counter = 0\n",
    "    not_found_counter = 0\n",
    "    for x in duplicated_similarity_score_list:\n",
    "        dup = x[1]\n",
    "        df = x[select_algorithm]\n",
    "        if df.loc[df['id'] == dup].empty:\n",
    "            not_found_counter +=1\n",
    "        else:\n",
    "            \n",
    "            found_counter +=1\n",
    "    print('Num of duplicated report found: ',found_counter)\n",
    "    print('Num of duplicated report not found: ',not_found_counter)\n",
    "    print('Recall (TP/TP+FN): ', round(found_counter/len(duplicated_similarity_score_list)*100,2),'%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word2vec_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>144</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>145</td>\n",
       "      <td>0.959616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>367</td>\n",
       "      <td>0.818042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543</td>\n",
       "      <td>1705</td>\n",
       "      <td>0.791714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>0.790835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>122</td>\n",
       "      <td>0.789630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>521</td>\n",
       "      <td>0.782684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1807</td>\n",
       "      <td>0.780917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2396</td>\n",
       "      <td>0.780185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>1012</td>\n",
       "      <td>0.776989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  word2vec_score\n",
       "64    144        1.000000\n",
       "65    145        0.959616\n",
       "243   367        0.818042\n",
       "543  1705        0.791714\n",
       "69    149        0.790835\n",
       "44    122        0.789630\n",
       "332   521        0.782684\n",
       "560  1807        0.780917\n",
       "640  2396        0.780185\n",
       "431  1012        0.776989"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_similarity_score_list[1][2]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Duplicate_BugReport_V7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
