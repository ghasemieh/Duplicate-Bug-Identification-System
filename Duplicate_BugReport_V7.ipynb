{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "Duplicate_BugReport_V7.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghasemieh/Duplicate-Bug-Identification-System/blob/master/Duplicate_BugReport_V7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7rGX36vDjHL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import progressbar as pb\n",
        "import time\n",
        "import warnings\n",
        "import text_processing as tp\n",
        "warnings.filterwarnings('ignore')\n",
        "# data = pd.read_csv('https://zenodo.org/record/400614/files/apache.csv?download=1',sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RBgiCkuNjHMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_nan(df):\n",
        "    print('Remove NA')\n",
        "    blanks = []\n",
        "    print(\"Before removing the NaN:\")\n",
        "    print(df.isnull().sum())\n",
        "    for x in df.itertuples():\n",
        "        if type(x.short_desc)!=str: # detect the NaN\n",
        "            blanks.append(x.Index)\n",
        "        elif not x.short_desc: # detect empty string\n",
        "            blanks.append(x.Index)\n",
        "    df.drop(blanks,inplace=True)\n",
        "    print(\"\\nAfter removing the NaN:\\n\",df.isnull().sum())\n",
        "    \n",
        "# remove_nan(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "d7KdZte2jHMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing the short_desc\n",
        "# processed_data_df = tp.text_preprocessing(data,\"short_desc\")\n",
        "# processed_data_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/processed_data_df.csv',index=False)\n",
        "# processed_data_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "mB2pQQh2jHME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data_df = pd.read_csv('~/Desktop/Google-Drive/Colab Notebooks/processed_data_df.csv',sep=',')\n",
        "# remove_nan(processed_data_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "scrolled": true,
        "id": "QUg7Pf9ajHMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model-1: Similarity Score - Word2vec -------------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import time\n",
        "import progressbar as pb\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "execution_count_word2vec = 0\n",
        "processed_data_nlp_df = []\n",
        "\n",
        "# Convert short_desc str to nlp format to fasten the computation process \n",
        "def word2vec_preprocess(df):\n",
        "    print('Convert short_desc str to nlp format')\n",
        "    sample_size = len(df)\n",
        "    progress = pb.ProgressBar(maxval = sample_size).start()\n",
        "    progvar  = 0\n",
        "    processed_data_nlp = []\n",
        "\n",
        "    for tup in df.itertuples():\n",
        "        processed_data_nlp.append((tup.id,tup.product,nlp(tup.short_desc_processed))) \n",
        "        progress.update(progvar + 1)\n",
        "        progvar += 1\n",
        "    \n",
        "    global processed_data_nlp_df\n",
        "    processed_data_nlp_df = pd.DataFrame(processed_data_nlp, columns=['id','product','short_desc_processed'])\n",
        "    global execution_count_word2vec\n",
        "    execution_count_word2vec += 1\n",
        "\n",
        "# Calculate the cosine similarity score\n",
        "def word2vec_similarity(id,df):\n",
        "    if execution_count_word2vec == 0:\n",
        "        word2vec_preprocess(df)\n",
        "#     print('Calculate the word2vec similarity score')\n",
        "#     start_time  = time.time()\n",
        "#     sample_size = len(processed_data_nlp_df)\n",
        "#     progress    = pb.ProgressBar(maxval=sample_size).start()\n",
        "#     progvar     = 0\n",
        "    similarities_score_list = []\n",
        "    \n",
        "    product_main = processed_data_nlp_df.loc[lambda df: df['id'] == id,'product'].array[0]\n",
        "    short_desc_processed_main = processed_data_nlp_df.loc[lambda df: df['id'] == id,'short_desc_processed'].array[0]\n",
        "    \n",
        "    for doc in processed_data_nlp_df.itertuples():\n",
        "        product_other = processed_data_nlp_df.loc[lambda df: df['id'] == doc.id,'product'].array[0]\n",
        "        if product_main == product_other:\n",
        "            similarity_score = doc.short_desc_processed.similarity(short_desc_processed_main)\n",
        "            similarities_score_list.append((doc.id,similarity_score))\n",
        "#         progress.update(progvar + 1)\n",
        "#         progvar += 1\n",
        "#     progress = pb.ProgressBar(maxval=sample_size).finish()\n",
        "\n",
        "    #convert to dataframe\n",
        "    word2vec_similarities_score_df = pd.DataFrame(similarities_score_list, columns=['id','word2vec_score'] )\n",
        "    word2vec_similarities_score_df = word2vec_similarities_score_df.reset_index(drop=True)\n",
        "    # show the time of process\n",
        "#     print(\"-word2vec- %s seconds ---\" % (time.time() - start_time)) \n",
        "    return word2vec_similarities_score_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "scrolled": true,
        "id": "0h94k80NjHMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model-2: Similarity Score - TF-idf ----------------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import time\n",
        "import progressbar as pb\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "tfidf_cosine_similarities = []\n",
        "execution_count_tfidf = 0\n",
        "\n",
        "def tfidf_preprocess(df):\n",
        "    X_train = df['short_desc_processed']\n",
        "    print('TF-idf Vectorization and similarity score computation')\n",
        "    # Vectorization\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform(X_train)\n",
        "    # Calculate the cosine similarity score\n",
        "    global tfidf_cosine_similarities\n",
        "    tfidf_cosine_similarities = linear_kernel(tfidf)\n",
        "    global shape_tfidf\n",
        "    shape_tfidf = tfidf_cosine_similarities.shape[0]\n",
        "    print('TF-idf preprocess done')\n",
        "    global execution_count_tfidf\n",
        "    execution_count_tfidf += 1\n",
        "\n",
        "def tfidf_similarities(id,df):\n",
        "    if execution_count_tfidf == 0:\n",
        "        tfidf_preprocess(df)\n",
        "#     print('Calculate the TF-idf similarity score')\n",
        "#     start_time   = time.time()\n",
        "#     sample_size  = len(df)\n",
        "#     progress     = pb.ProgressBar(maxval = sample_size).start()\n",
        "#     progvar      = 0\n",
        "    index_main   = df.loc[lambda df: df['id'] == id].index.array[0]\n",
        "    product_main = df.loc[lambda df: df['id'] == id,'product'].array[0]\n",
        "    tfidf_cosine_similarities_list = []\n",
        "    for index_other in range(shape_tfidf):\n",
        "        id_other      = df.iloc[index_other]['id']\n",
        "        product_other = df.iloc[index_other]['product']\n",
        "        if product_main == product_other:\n",
        "            tfidf_cosine_similarities_list.append([id_other,tfidf_cosine_similarities[index_main,index_other]])\n",
        "#         progress.update(progvar + 1)\n",
        "#         progvar += 1\n",
        "#     progress = pb.ProgressBar(maxval=sample_size).finish()\n",
        "\n",
        "    #Conver to dataframe\n",
        "    tfidf_cosine_similarities_score_df = pd.DataFrame(tfidf_cosine_similarities_list, columns=['id','tfidf_score'])\n",
        "    tfidf_cosine_similarities_score_df = tfidf_cosine_similarities_score_df.reset_index(drop=True)\n",
        "    # show the time of process\n",
        "#     print(\"-TF-idf- %s seconds ---\" % (time.time() - start_time)) \n",
        "    return tfidf_cosine_similarities_score_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "peX-AaKqjHML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model-3: Similarity Score - BM24F -----------------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import time\n",
        "import progressbar as pb\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "processed_corpus_list = []\n",
        "bm25 = []\n",
        "execution_count_bm25 = 0\n",
        "\n",
        "# preprocess - tokenize the short_desc to token\n",
        "def bm24_preprocess(df):\n",
        "    print('preprocess - tokenize the short_desc to token')\n",
        "    sample_size = len(df)\n",
        "    global processed_corpus_list\n",
        "    processed_corpus_list = []\n",
        "    for x in df.itertuples():\n",
        "        short_desc_splited = x.short_desc_processed.split(\" \")\n",
        "        processed_corpus_list.append(short_desc_splited)\n",
        "    # Create a MB24 Object with the corpus\n",
        "    global bm25\n",
        "    bm25 = BM25Okapi(processed_corpus_list)\n",
        "    global execution_count_bm25\n",
        "    execution_count_bm25 += 1\n",
        "    \n",
        "# Calculate the similarity score\n",
        "def bm24_similarity(id,df):\n",
        "    if execution_count_bm25 == 0:\n",
        "        bm24_preprocess(df)\n",
        "#     print('Calculate the BM24 similarity score')\n",
        "#     start_time    = time.time()\n",
        "#     sample_size   = len(df)\n",
        "#     progress      = pb.ProgressBar(maxval = sample_size).start()\n",
        "#     progvar       = 0\n",
        "    index_main    = df.loc[lambda df: df['id'] == id].index.array[0]\n",
        "    product_main  = df.loc[lambda df: df['id'] == id,'product'].array[0]\n",
        "    query         = processed_corpus_list[index_main]\n",
        "    doc_scores    = bm25.get_scores(query)\n",
        "    doc_scores_df = pd.DataFrame(doc_scores, columns=['bm24_score'])\n",
        "    \n",
        "    # add id to the score list and remove unsimiliar product\n",
        "    blanks = []\n",
        "    for x in doc_scores_df.itertuples():\n",
        "        id_other      = df.iloc[x.Index]['id']\n",
        "        product_other = df.iloc[x.Index]['product']\n",
        "        # add id to the score list\n",
        "        doc_scores_df.loc[x.Index,'id'] = id_other\n",
        "        if product_main != product_other:\n",
        "            blanks.append(x.Index)    \n",
        "#         progress.update(progvar + 1)\n",
        "#         progvar += 1\n",
        "    doc_scores_df.drop(blanks,inplace=True)   \n",
        "    doc_scores_df = doc_scores_df.reset_index(drop = True) \n",
        "    # show the time of process\n",
        "#     print(\"-bm24- %s seconds ---\" % (time.time() - start_time)) \n",
        "    return doc_scores_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im6ELB6AjHMN",
        "colab_type": "text"
      },
      "source": [
        "Assessment the Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ncLBbVjAjHMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assessment the Model Accuracy -------------------------------------------------------------------------------\n",
        "# duplicate_df = pd.read_csv('https://zenodo.org/record/400614/files/apache.relations.csv?download=1',sep=',')\n",
        "# duplicate_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/duplicate_df.csv',index=False)\n",
        "duplicate_df = pd.read_csv('~/Desktop/Google-Drive/Colab Notebooks/duplicate_df.csv',sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3LiKcSDojHMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the similarity scores and return the first n top scoes\n",
        "def similarity_score(id, df,top_n):\n",
        "    word2vec_similarity_df = word2vec_similarity(id, df).sort_values(by=['word2vec_score'],ascending=False).head(top_n)\n",
        "    tfidf_similarity_df    = tfidf_similarities(id, df).sort_values(by=['tfidf_score'],ascending=False).head(top_n)\n",
        "    bm24_similarity_df     = bm24_similarity(id, df).sort_values(by=['bm24_score'],ascending=False).head(top_n)    \n",
        "    return word2vec_similarity_df, tfidf_similarity_df, bm24_similarity_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eI6Y_e_5jHMS",
        "colab_type": "code",
        "colab": {},
        "outputId": "94268c53-238d-43c6-cb39-be7fd56f41f6"
      },
      "source": [
        "# Calculate the similarity score for the reported duplicated bug report\n",
        "import progressbar as pb\n",
        "import time\n",
        "start_time  = time.time()\n",
        "sample_size = len(duplicate_df)\n",
        "progress    = pb.ProgressBar(maxval = sample_size).start()\n",
        "progvar     = 0\n",
        "duplicated_similarity_score_list = []\n",
        "\n",
        "for tup in duplicate_df.itertuples():\n",
        "    word2vec_similarity_df, tfidf_similarity_df, bm24_similarity_df = similarity_score(tup.id, processed_data_df,20)\n",
        "    duplicated_similarity_score_list.append([tup.id,tup.dup,word2vec_similarity_df,tfidf_similarity_df,bm24_similarity_df])\n",
        "    progress.update(progvar + 1)\n",
        "    progvar += 1\n",
        "    \n",
        "print(\"-Total- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 13% (68 of 500) |###                    | Elapsed Time: 1:05:56 ETA:   6:57:36"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Epxe2-vWjHMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(\"duplicated_similarity_score_list.txt\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(duplicated_similarity_score_list, fp)\n",
        "\n",
        "# with open(\"duplicated_similarity_score_list.txt\", \"rb\") as fp:   # Unpickling\n",
        "#     l = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}