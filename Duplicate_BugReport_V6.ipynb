{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading en_core_web_lg\n",
      "Loading the dataframe\n",
      "Load is complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import progressbar as pb\n",
    "import time\n",
    "import warnings\n",
    "import text_processing as tp\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Loading the dataframe')\n",
    "# data = pd.read_csv('https://zenodo.org/record/400614/files/apache.csv?download=1',sep=',')\n",
    "print('Load is complete')\n",
    "# sample_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def remove_nan(df):\n",
    "    print('Remove NA')\n",
    "    blanks = []\n",
    "    print(\"Before removing the NaN:\")\n",
    "    print(df.isnull().sum())\n",
    "    for x in df.itertuples():\n",
    "        if type(x.short_desc)!=str: # detect the NaN\n",
    "            blanks.append(x.Index)\n",
    "        elif not x.short_desc: # detect empty string\n",
    "            blanks.append(x.Index)\n",
    "    df.drop(blanks,inplace=True)\n",
    "    print(\"\\nAfter removing the NaN:\\n\",df.isnull().sum())\n",
    "    \n",
    "# remove_nan(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing the short_desc\n",
    "# processed_data_df = tp.text_preprocessing(data,\"short_desc\")\n",
    "# processed_data_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/processed_data_df.csv',index=False)\n",
    "# print(processed_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "processed_data_df = pd.read_csv('~/Desktop/Google-Drive/Colab Notebooks/processed_data_df.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# # Model-1: Similarity Score - Word2vec -------------------------------------------------------------------------------\n",
    "# # Calculate similarity score Using word2vec\n",
    "# print('Model-1: Similarity Score - Word2vec')\n",
    "# sample_size = len(processed_data_df)\n",
    "# start_time = time.time()\n",
    "\n",
    "# import spacy\n",
    "# print('Loading en_core_web_lg')\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# # Convert short_desc str to nlp format to fasten the computation process\n",
    "# print('Convert short_desc str to nlp format to fasten the computation process')\n",
    "# progress = pb.ProgressBar(maxval=sample_size).start()\n",
    "# progvar = 0\n",
    "# processed_data_nlp = []\n",
    "\n",
    "# for tup in processed_data_df.itertuples():\n",
    "#     processed_data_nlp.append((tup.id,tup.product,nlp(tup.short_desc)))\n",
    "#     progress.update(progvar + 1)\n",
    "#     progvar += 1\n",
    "# progress = pb.ProgressBar(maxval=sample_size).finish()\n",
    "\n",
    "# processed_data_nlp_df = pd.DataFrame(processed_data_nlp, columns=['id','product','short_desc'])\n",
    "# processed_data_nlp_df.head()\n",
    "# del processed_data_nlp\n",
    "\n",
    "# # Calculate the cosine similarity score\n",
    "# print('Calculate the similarity score')\n",
    "# progress = pb.ProgressBar(maxval=sample_size).start()\n",
    "# progvar = 0\n",
    "# similarities_score_list = []\n",
    "\n",
    "# for doc1 in processed_data_nlp_df.itertuples():\n",
    "#     for doc2 in processed_data_nlp_df.itertuples():\n",
    "#         if (doc1.id < doc2.id) and (doc1.product == doc2.product): # if two bug reports belong to the same product then check the similarity\n",
    "#             similarity_score = doc1.short_desc.similarity(doc2.short_desc,)\n",
    "#             similarities_score_list.append((doc1.id,doc2.id,similarity_score))\n",
    "#     progress.update(progvar + 1)\n",
    "#     progvar += 1\n",
    "# progress = pb.ProgressBar(maxval=sample_size).finish()\n",
    "\n",
    "# #convert to dataframe\n",
    "# word2vec_similarities_score_df = pd.DataFrame(similarities_score_list, columns=['id1','id2','word2vec_score'] )\n",
    "# del similarities_score_list\n",
    "# word2vec_similarities_score_df = word2vec_similarities_score_df.reset_index(drop=True)\n",
    "# word2vec_similarities_score_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/word2vec_similarities_score_df.csv',index=False)\n",
    "# print(\"-Total- %s seconds ---\" % (time.time() - start_time)) # show the time of process\n",
    "# print('word2vec_similarities_score_df Shape:')\n",
    "# print(word2vec_similarities_score_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-2: Similarity Score - tf-idf\n",
      "Calculate the similarity score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (1679 of 43991) |                   | Elapsed Time: 0:01:13 ETA:   0:44:42"
     ]
    }
   ],
   "source": [
    "# Model-2: Similarity Score - tf-idf -----------------------------------------------------------------------------------\n",
    "print('Model-2: Similarity Score - tf-idf')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "start_time = time.time()\n",
    "X_train = processed_data_df['short_desc']\n",
    "sample_size = len(processed_data_df)\n",
    "# Vectorization \n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(X_train) # remember to use the original X_train set\n",
    "\n",
    "# Calculate the cosine similarity score\n",
    "print('Calculate the similarity score')\n",
    "tfidf_cosine_similarities = linear_kernel(tfidf)\n",
    "shape = tfidf_cosine_similarities.shape[0]\n",
    "tfidf_cosine_similarities_list = []\n",
    "progress = pb.ProgressBar(maxval=sample_size).start()\n",
    "progvar = 0\n",
    "for index1 in range(shape):\n",
    "    for index2 in range(shape):\n",
    "        if index2 > index1:\n",
    "            tfidf_cosine_similarities_list.append([index1,index2,tfidf_cosine_similarities[index1,index2]])\n",
    "    progress.update(progvar + 1)\n",
    "    progvar += 1\n",
    "progress = pb.ProgressBar(maxval=sample_size).finish()\n",
    "\n",
    "#Conver to dataframe\n",
    "tfidf_cosine_similarities_score_df = pd.DataFrame(tfidf_cosine_similarities_list, columns=['id1','id2','tfidf_score'])\n",
    "del tfidf_cosine_similarities_list\n",
    "\n",
    "# Convert index to id and Remove record of diff product\n",
    "tp.index_to_id_remove_diff_product_score(tfidf_cosine_similarities_score_df, data)\n",
    "\n",
    "tfidf_cosine_similarities_score_df = tfidf_cosine_similarities_score_df.reset_index(drop=True)\n",
    "tfidf_cosine_similarities_score_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/tfidf_cosine_similarities_score_df.csv',index=False)\n",
    "print(\"-Total- %s seconds ---\" % (time.time() - start_time)) # show the time of process\n",
    "print('tfidf_cosine_similarities_score_df Shape:')\n",
    "print(tfidf_cosine_similarities_score_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Model-3: Similarity Score - BM24F ------------------------------------------------------------------------------------\n",
    "print('Model-3: Similarity Score - BM24F')\n",
    "from rank_bm25 import BM25Okapi\n",
    "progress = pb.ProgressBar(maxval=sample_size).start()\n",
    "progvar = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# preprocess - tokenize the short_desc to token\n",
    "print('preprocess - tokenize the short_desc to token')\n",
    "processed_corpus_list = []\n",
    "\n",
    "for x in processed_data_df.itertuples():\n",
    "    short_desc_splited = x.short_desc.split(\" \")\n",
    "    processed_corpus_list.append(short_desc_splited)\n",
    "    \n",
    "# Create a MB24 Object with the corpus\n",
    "bm25 = BM25Okapi(processed_corpus_list)\n",
    "\n",
    "# Calculate the similarity score for all bug reports\n",
    "BM24_similarity_score_list = []\n",
    "\n",
    "for x in processed_data_df.itertuples():\n",
    "    query = processed_corpus_list[x.Index]\n",
    "    doc_scores = bm25.get_scores(query)\n",
    "    BM24_similarity_score_list.append([x.Index,doc_scores])\n",
    "\n",
    "# Re-formating Matrix to List\n",
    "print('Reformating Matrix to List')\n",
    "shape = doc_scores.shape[0]\n",
    "BM24_similarity_score_list_2 = []\n",
    "\n",
    "for index1 in range(shape):\n",
    "    for index2 in range(shape):\n",
    "        if index2 > index1:\n",
    "            BM24_similarity_score_list_2.append([index1,index2,BM24_similarity_score_list[index1][1][index2]])\n",
    "    progress.update(progvar + 1)\n",
    "    progvar += 1\n",
    "progress = pb.ProgressBar(maxval=sample_size).finish()\n",
    "\n",
    "del BM24_similarity_score_list\n",
    "\n",
    "# Conver to dataframe\n",
    "BM24_similarity_score_sort_df = pd.DataFrame(BM24_similarity_score_list_2, columns=['id1','id2','BM24_score'])\n",
    "del BM24_similarity_score_list_2\n",
    "\n",
    "# Convert index to id and Remove record of diff product\n",
    "tp.index_to_id_remove_diff_product_score(BM24_similarity_score_sort_df,data)\n",
    "\n",
    "BM24_similarity_score_sort_df = BM24_similarity_score_sort_df.reset_index(drop=True)\n",
    "BM24_similarity_score_sort_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/BM24_similarity_score_sort_df.csv',index=False)\n",
    "print(\"-Total- %s seconds ---\" % (time.time() - start_time)) # show the time of process\n",
    "print('BM24_similarity_score_sort_df Shape:')\n",
    "print(BM24_similarity_score_sort_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessment the Model Accuracy ----------------------------------------------------------------------------------------\n",
    "print('Assessment the Model Accuracy')\n",
    "duplicate_org = pd.read_csv('https://zenodo.org/record/400614/files/apache.relations.csv?download=1',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_df = tp.id_builder(word2vec_similarities_score_df)\n",
    "tfidf_df = tp.id_builder(tfidf_cosine_similarities_score_df)\n",
    "BM24_df = tp.id_builder(BM24_similarity_score_sort_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_score = pd.merge(word2vec_df, tfidf_df, on = 'ID')\n",
    "total_score = pd.merge(total_score, BM24_df, on = 'ID')\n",
    "total_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[2, 3], [2, 27],[2,31]]), columns=['id', 'dup'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "progress = pb.ProgressBar(maxval=len(df)).start()\n",
    "progvar = 0\n",
    "start_time = time.time()\n",
    "duplicate_score_table_list = []\n",
    "\n",
    "for tup in df.itertuples():\n",
    "    \n",
    "    word2vec_score = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'word2vec_score'].array[0]\n",
    "    tfidf_score = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'tfidf_score'].array[0]\n",
    "    BM24_score  = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'BM24_score'].array[0]\n",
    "    short_desc1 = data.loc[lambda df: df['id'] == tup.id,'short_desc'].array[0]\n",
    "    short_desc2 = data.loc[lambda df: df['id'] == tup.dup,'short_desc'].array[0]\n",
    "    \n",
    "    duplicate_score_table_list.append([tup.id,tup.dup,word2vec_score,tfidf_score,BM24_score,short_desc1,short_desc2])\n",
    "\n",
    "    progress.update(progvar + 1)\n",
    "    progvar += 1\n",
    "    \n",
    "duplicate_score_table_df = pd.DataFrame(duplicate_score_table_list, columns=['id','dup','word2vec_score','tfidf_score','BM24_score','short_desc1','short_desc2'])\n",
    "del duplicate_score_table_list\n",
    "duplicate_score_table_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/duplicate_score_table_df.csv',index=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) # show the time of process\n",
    "duplicate_score_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "progress = pb.ProgressBar(maxval=len(df)).start()\n",
    "progvar = 0\n",
    "start_time = time.time()\n",
    "duplicate_score_table_list = []\n",
    "\n",
    "for tup in df.itertuples():\n",
    "    \n",
    "    word2vec_score = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'word2vec_score'].array[0]\n",
    "    tfidf_score = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'tfidf_score'].array[0]\n",
    "    BM24_score  = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'BM24_score'].array[0]\n",
    "    short_desc1 = data.loc[lambda df: df['id'] == tup.id,'short_desc'].array[0]\n",
    "    short_desc2 = data.loc[lambda df: df['id'] == tup.dup,'short_desc'].array[0]\n",
    "    \n",
    "    duplicate_score_table_list.append([tup.id,tup.dup,word2vec_score,tfidf_score,BM24_score,short_desc1,short_desc2])\n",
    "\n",
    "    progress.update(progvar + 1)\n",
    "    progvar += 1\n",
    "    \n",
    "duplicate_score_table_df = pd.DataFrame(duplicate_score_table_list, columns=['id','dup','word2vec_score','tfidf_score','BM24_score','short_desc1','short_desc2'])\n",
    "del duplicate_score_table_list\n",
    "duplicate_score_table_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/duplicate_score_table_df.csv',index=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) # show the time of process\n",
    "duplicate_score_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[2, 3], [2, 27],[2,31]]), columns=['id', 'dup'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "progress = pb.ProgressBar(maxval=len(df)).start()\n",
    "progvar = 0\n",
    "start_time = time.time()\n",
    "duplicate_score_table_list = []\n",
    "\n",
    "for tup in df.itertuples():\n",
    "    \n",
    "    word2vec_score = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'word2vec_score'].array[0]\n",
    "    tfidf_score = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'tfidf_score'].array[0]\n",
    "    BM24_score  = total_score.loc[(total_score['id1'] == tup.id) & (total_score['id2'] == tup.dup),'BM24_score'].array[0]\n",
    "    short_desc1 = data.loc[lambda df: df['id'] == tup.id,'short_desc'].array[0]\n",
    "    short_desc2 = data.loc[lambda df: df['id'] == tup.dup,'short_desc'].array[0]\n",
    "    \n",
    "    duplicate_score_table_list.append([tup.id,tup.dup,word2vec_score,tfidf_score,BM24_score,short_desc1,short_desc2])\n",
    "\n",
    "    progress.update(progvar + 1)\n",
    "    progvar += 1\n",
    "    \n",
    "duplicate_score_table_df = pd.DataFrame(duplicate_score_table_list, columns=['id','dup','word2vec_score','tfidf_score','BM24_score','short_desc1','short_desc2'])\n",
    "del duplicate_score_table_list\n",
    "duplicate_score_table_df.to_csv('~/Desktop/Google-Drive/Colab Notebooks/duplicate_score_table_df.csv',index=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) # show the time of process\n",
    "duplicate_score_table_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
