{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-idf PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "data = spark.read.csv(\"Data/processed_TestData2500_df.csv\",inferSchema=True,header=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"short_desc_processed\", outputCol=\"token_short_desc_processed\")\n",
    "count_vec = CountVectorizer(inputCol='token_short_desc_processed',outputCol='c_vec')\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[tokenizer,count_vec,idf])\n",
    "cleaner = data_prep_pipe.fit(data)\n",
    "clean_data = cleaner.transform(data)\n",
    "clean_data = clean_data.select(['id','product','tf_idf'])\n",
    "tfidf = clean_data.select(['tf_idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id| product|              tf_idf|\n",
      "+---+--------+--------------------+\n",
      "|  2| Log4j -|(1590,[49,404,572...|\n",
      "|  3| Log4j -|(1590,[4,738],[2....|\n",
      "| 22|Apache h|(1590,[3,39,62,27...|\n",
      "| 27| Log4j -|(1590,[3,190,199]...|\n",
      "| 29| Log4j -|(1590,[3,59,92,11...|\n",
      "| 31| Log4j -|(1590,[44,49,123,...|\n",
      "| 32| Log4j -|(1590,[424],[5.76...|\n",
      "| 34| Log4j -|(1590,[8,95,112,6...|\n",
      "| 35| Log4j -|(1590,[121,127,47...|\n",
      "| 43| Log4j -|(1590,[0,193,395,...|\n",
      "| 44| Log4j -|(1590,[3,156],[2....|\n",
      "| 45| Batik -|(1590,[30,34,45,2...|\n",
      "| 46| Batik -|(1590,[30,34,618]...|\n",
      "| 47| Batik -|(1590,[292,618,88...|\n",
      "| 48| Batik -|(1590,[0,452,839,...|\n",
      "| 49| Batik -|(1590,[619,1124,1...|\n",
      "| 50| Batik -|(1590,[74,190,195...|\n",
      "| 51| Batik -|(1590,[35,212,541...|\n",
      "| 52| Batik -|(1590,[93,225,312...|\n",
      "| 53| Batik -|(1590,[116,219,61...|\n",
      "+---+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-2: Similarity Score - TF-idf ----------------------------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "tfidf_cosine_similarities = []\n",
    "execution_count_tfidf = 0\n",
    "\n",
    "def tfidf_preprocess_pyspark(id,df):\n",
    "    X_train = df['short_desc_processed']\n",
    "    print('TF-idf Vectorization and similarity score computation')\n",
    "    # Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(X_train)\n",
    "    # Calculate the cosine similarity score\n",
    "    tfidf_cosine_similarities = linear_kernel(tfidf)\n",
    "    print('TF-idf preprocess done')\n",
    "    \n",
    "    index_main   = df.loc[lambda df: df['id'] == id].index.array[0]\n",
    "    product_main = df.loc[lambda df: df['id'] == id,'product'].array[0]\n",
    "    tfidf_cosine_similarities_list = []\n",
    "    for index_other in range(shape_tfidf):\n",
    "        id_other      = df.iloc[index_other]['id']\n",
    "        product_other = df.iloc[index_other]['product']\n",
    "        if product_main == product_other:\n",
    "            tfidf_cosine_similarities_list.append([id_other,tfidf_cosine_similarities[index_main,index_other]])\n",
    "    #Conver to dataframe\n",
    "    tfidf_cosine_similarities_score_df = pd.DataFrame(tfidf_cosine_similarities_list, columns=['id','tfidf_score'])\n",
    "    tfidf_cosine_similarities_score_df = tfidf_cosine_similarities_score_df.reset_index(drop=True)\n",
    "    return tfidf_cosine_similarities_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, struct, col\n",
    "from pyspark.sql.types import * \n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"tfidf_score\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_udf = udf(lambda z: tfidf_preprocess_pyspark(id, df), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b7b5089d21ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_new = df.select('id', tfidf_udf(2,processed_data_df))\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
